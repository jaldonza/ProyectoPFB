{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.5.2-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\rober\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.5.2-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rober\\AppData\\Local\\Temp\\ipykernel_25184\\462899246.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conexion)\n"
     ]
    }
   ],
   "source": [
    "# Conexión a la base de datos\n",
    "conexion = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user=\"root\",  \n",
    "    password=\"Mysql123\",\n",
    "    database=\"yfinance\"  \n",
    ")\n",
    "\n",
    "# Carga de datos desde una consulta SQL a un DataFrame\n",
    "query = \"SELECT precios_historicos.precio_apertura,precios_historicos.precio_cierre,precios_historicos.maximo,precios_historicos.minimo,precios_historicos.volumen,empresas_sp500.sector,empresas_sp500.industria FROM precios_historicos INNER JOIN empresas_sp500 ON precios_historicos.id_empresa = empresas_sp500.id_empresa;\"\n",
    "df = pd.read_sql(query, conexion)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rober\\AppData\\Local\\Temp\\ipykernel_25184\\3439496553.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  empresas_df = pd.read_sql(query, conexion)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precio_apertura</th>\n",
       "      <th>precio_cierre</th>\n",
       "      <th>maximo</th>\n",
       "      <th>minimo</th>\n",
       "      <th>volumen</th>\n",
       "      <th>sector</th>\n",
       "      <th>industria</th>\n",
       "      <th>sector_encoded</th>\n",
       "      <th>industria_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.1681</td>\n",
       "      <td>19.8138</td>\n",
       "      <td>20.2600</td>\n",
       "      <td>19.7482</td>\n",
       "      <td>2599386</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.4989</td>\n",
       "      <td>19.0265</td>\n",
       "      <td>19.9057</td>\n",
       "      <td>19.0265</td>\n",
       "      <td>3245705</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.1315</td>\n",
       "      <td>19.5776</td>\n",
       "      <td>20.2075</td>\n",
       "      <td>19.1315</td>\n",
       "      <td>4424482</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.8007</td>\n",
       "      <td>21.1523</td>\n",
       "      <td>21.5197</td>\n",
       "      <td>19.8007</td>\n",
       "      <td>7147057</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.2310</td>\n",
       "      <td>21.5721</td>\n",
       "      <td>21.7952</td>\n",
       "      <td>20.9817</td>\n",
       "      <td>4905035</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precio_apertura  precio_cierre   maximo   minimo  volumen       sector  \\\n",
       "0          20.1681        19.8138  20.2600  19.7482  2599386  Industrials   \n",
       "1          19.4989        19.0265  19.9057  19.0265  3245705  Industrials   \n",
       "2          19.1315        19.5776  20.2075  19.1315  4424482  Industrials   \n",
       "3          19.8007        21.1523  21.5197  19.8007  7147057  Industrials   \n",
       "4          21.2310        21.5721  21.7952  20.9817  4905035  Industrials   \n",
       "\n",
       "                  industria  sector_encoded  industria_encoded  \n",
       "0  Industrial Conglomerates               6                 67  \n",
       "1  Industrial Conglomerates               6                 67  \n",
       "2  Industrial Conglomerates               6                 67  \n",
       "3  Industrial Conglomerates               6                 67  \n",
       "4  Industrial Conglomerates               6                 67  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conexion = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user=\"root\",  \n",
    "    password=\"Mysql123\",\n",
    "    database=\"yfinance\")\n",
    "\n",
    "query = \"SELECT precios_historicos.precio_apertura,precios_historicos.precio_cierre,precios_historicos.maximo,precios_historicos.minimo,precios_historicos.volumen,empresas_sp500.sector,empresas_sp500.industria FROM precios_historicos INNER JOIN empresas_sp500 ON precios_historicos.id_empresa = empresas_sp500.id_empresa;\"\n",
    "empresas_df = pd.read_sql(query, conexion)\n",
    "\n",
    "### encoder sector\n",
    "\n",
    "label_encoder_sector = LabelEncoder()\n",
    "empresas_df['sector_encoded'] = label_encoder_sector.fit_transform(empresas_df['sector'])\n",
    "\n",
    "### encoder industria\n",
    "\n",
    "label_encoder_industria = LabelEncoder()\n",
    "empresas_df['industria_encoded'] = label_encoder_industria.fit_transform(empresas_df['industria'])\n",
    "\n",
    "###\n",
    "\n",
    "empresas_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   precio_apertura  precio_cierre   maximo   minimo  volumen       sector  \\\n",
      "0          20.1681        19.8138  20.2600  19.7482  2599386  Industrials   \n",
      "1          19.4989        19.0265  19.9057  19.0265  3245705  Industrials   \n",
      "2          19.1315        19.5776  20.2075  19.1315  4424482  Industrials   \n",
      "3          19.8007        21.1523  21.5197  19.8007  7147057  Industrials   \n",
      "4          21.2310        21.5721  21.7952  20.9817  4905035  Industrials   \n",
      "\n",
      "                  industria  \n",
      "0  Industrial Conglomerates  \n",
      "1  Industrial Conglomerates  \n",
      "2  Industrial Conglomerates  \n",
      "3  Industrial Conglomerates  \n",
      "4  Industrial Conglomerates  \n"
     ]
    }
   ],
   "source": [
    "# Simular datos de ejemplo\n",
    "np.random.seed(42)\n",
    "\n",
    "x = empresas_df[['precio_apertura','precio_cierre','maximo','minimo','volumen']]\n",
    "y = empresas_df[['sector_encoded','industria_encoded']]\n",
    "\n",
    "# Ejecutar K-Means para agrupar las acciones\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "empresas_df = kmeans.fit_predict(empresas_df[['precio_apertura','precio_cierre','maximo','minimo','volumen']])\n",
    "\n",
    "print(df.head())  # Visualizar las características y el cluster asignado\n",
    "\n",
    "conexion.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos preparados:\n",
      "Tamaño de X_train: (2205567, 5), X_test: (551392, 5)\n",
      "Tamaño de y_train: (2205567, 2), y_test: (551392, 2)\n"
     ]
    }
   ],
   "source": [
    "# Dividir el conjunto de datos en entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Datos preparados:\")\n",
    "print(f\"Tamaño de X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"Tamaño de y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rober\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida 1:\n",
      "Matriz de Confusión:\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Rober\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (slice(None, None, None), 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSalida \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatriz de Confusión:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28mprint\u001b[39m(confusion_matrix(\u001b[43my_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, y_pred[:, i]))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mReporte de Clasificación:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test[:, i], y_pred[:, i]))\n",
      "File \u001b[1;32mc:\\Users\\Rober\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Rober\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3811\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[1;32m-> 3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m   3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 0)"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "modelo = RandomForestClassifier(n_estimators=20,max_depth=10,max_features= 'sqrt', random_state=42)\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones en los datos de prueba\n",
    "pca = PCA(n_components=5)  # Reduce a 5 componentes principales\n",
    "X_test_reduced = pca.fit_transform(X_test)\n",
    "y_pred = modelo.predict(X_test_reduced)\n",
    "\n",
    "\n",
    "for i in range(y_test.shape[1]):  \n",
    "    print(f\"Salida {i + 1}:\")\n",
    "    print(\"Matriz de Confusión:\")\n",
    "    print(confusion_matrix(y_test[:, i], y_pred[:, i]))\n",
    "    print(\"\\nReporte de Clasificación:\")\n",
    "    print(classification_report(y_test[:, i], y_pred[:, i]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
